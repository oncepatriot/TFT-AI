Logging to logs

Setting up the selfplay training environment opponents...
Saving base.zip PPO model...

Loading the base PPO agent to train...

Setting up the selfplay evaluation environment opponents...
Loading base.zip

Setup complete - commencing learning...

********** Iteration 0 ************
Optimizing...
     pol_surr |    pol_entpen |       vf_loss |            kl |           ent
      0.04166 |      -0.00043 |       1.13155 |       0.08682 |       4.33190
      0.04130 |      -0.00044 |       1.01298 |       0.09779 |       4.36360
      0.06164 |      -0.00043 |       0.02201 |       0.13561 |       4.32312
      0.05548 |      -0.00043 |       0.01747 |       0.12002 |       4.31509
Evaluating losses...
      0.04389 |      -0.00043 |       0.02584 |       0.09892 |       4.32306
-----------------------------------
| EpLenMean       | 1.79e+03      |
| EpRewMean       | 0             |
| EpThisIter      | 2             |
| EpisodesSoFar   | 2             |
| TimeElapsed     | 488           |
| TimestepsSoFar  | 4096          |
| ev_tdlam_before | 0.287         |
| loss_ent        | 4.323065      |
| loss_kl         | 0.09891617    |
| loss_pol_entpen | -0.0004323065 |
| loss_pol_surr   | 0.04388853    |
| loss_vf_loss    | 0.025837023   |
-----------------------------------
********** Iteration 1 ************
Eval num_timesteps=4096, episode_reward=0.00 +/- 0.00
Total episodes ran=1
Optimizing...
     pol_surr |    pol_entpen |       vf_loss |            kl |           ent
     -0.00062 |      -0.00043 |       0.01425 |       0.00184 |       4.33907
     -0.00319 |      -0.00044 |       0.00938 |       0.01055 |       4.37076
     -0.00559 |      -0.00044 |       0.00342 |       0.01213 |       4.38348
     -0.00888 |      -0.00044 |       0.00231 |       0.01140 |       4.36055
Evaluating losses...
     -0.01313 |      -0.00044 |       0.00413 |       0.01068 |       4.35260
------------------------------------
| EpLenMean       | 1.95e+03       |
| EpRewMean       | 0              |
| EpThisIter      | 2              |
| EpisodesSoFar   | 4              |
| TimeElapsed     | 1.32e+03       |
| TimestepsSoFar  | 8192           |
| ev_tdlam_before | 0.295          |
| loss_ent        | 4.352603       |
| loss_kl         | 0.010680157    |
| loss_pol_entpen | -0.00043526027 |
| loss_pol_surr   | -0.013127774   |
| loss_vf_loss    | 0.004134709    |
------------------------------------
********** Iteration 2 ************
Eval num_timesteps=8192, episode_reward=0.00 +/- 0.00
Total episodes ran=1
Optimizing...
     pol_surr |    pol_entpen |       vf_loss |            kl |           ent
     -0.00049 |      -0.00043 |       0.00075 |       0.00140 |       4.34850
     -0.00395 |      -0.00043 |       0.00106 |       0.00757 |       4.33807
     -0.00771 |      -0.00043 |       0.00034 |       0.00958 |       4.33413
     -0.01105 |      -0.00043 |       0.00030 |       0.00784 |       4.34083
Evaluating losses...
     -0.01344 |      -0.00043 |       0.00017 |       0.00806 |       4.34782
------------------------------------
| EpLenMean       | 1.99e+03       |
| EpRewMean       | 0              |
| EpThisIter      | 1              |
| EpisodesSoFar   | 5              |
| TimeElapsed     | 2.08e+03       |
| TimestepsSoFar  | 12288          |
| ev_tdlam_before | 0.315          |
| loss_ent        | 4.347821       |
| loss_kl         | 0.00806147     |
| loss_pol_entpen | -0.00043478212 |
| loss_pol_surr   | -0.013442954   |
| loss_vf_loss    | 0.00016937789  |
------------------------------------
********** Iteration 3 ************
Eval num_timesteps=12288, episode_reward=3.00 +/- 0.00
Total episodes ran=1
New best model: 1

Optimizing...
     pol_surr |    pol_entpen |       vf_loss |            kl |           ent
     -0.00046 |      -0.00043 |       0.00025 |       0.00030 |       4.34853
     -0.00596 |      -0.00043 |       0.00016 |       0.00353 |       4.34596
     -0.00870 |      -0.00043 |       0.00042 |       0.01134 |       4.33186
     -0.01307 |      -0.00043 |       0.00029 |       0.00990 |       4.32734
Evaluating losses...
     -0.01379 |      -0.00043 |      9.52e-05 |       0.00911 |       4.32989
------------------------------------
| EpLenMean       | 2.13e+03       |
| EpRewMean       | 0              |
| EpThisIter      | 2              |
| EpisodesSoFar   | 7              |
| TimeElapsed     | 2.82e+03       |
| TimestepsSoFar  | 16384          |
| ev_tdlam_before | 0.328          |
| loss_ent        | 4.3298917      |
| loss_kl         | 0.009109896    |
| loss_pol_entpen | -0.00043298915 |
| loss_pol_surr   | -0.013791543   |
| loss_vf_loss    | 9.521755e-05   |
------------------------------------
********** Iteration 4 ************
Loading _model_00001_0_3.0_12288_.zip
Optimizing...
     pol_surr |    pol_entpen |       vf_loss |            kl |           ent
      0.00035 |      -0.00043 |       0.00024 |       0.00048 |       4.33046
     -0.00243 |      -0.00043 |       0.00011 |       0.00332 |       4.31977
     -0.00648 |      -0.00043 |       0.00022 |       0.00657 |       4.30404
     -0.01023 |      -0.00043 |       0.00013 |       0.00818 |       4.29687
Evaluating losses...
     -0.01259 |      -0.00043 |       0.00031 |       0.00899 |       4.29766
------------------------------------
| EpLenMean       | 2.17e+03       |
| EpRewMean       | 0              |
| EpThisIter      | 2              |
| EpisodesSoFar   | 9              |
| TimeElapsed     | 3.3e+03        |
| TimestepsSoFar  | 20480          |
| ev_tdlam_before | 0.193          |
| loss_ent        | 4.2976637      |
| loss_kl         | 0.008991735    |
| loss_pol_entpen | -0.00042976634 |
| loss_pol_surr   | -0.012592486   |
| loss_vf_loss    | 0.0003065102   |
------------------------------------
********** Iteration 5 ************
Loading _model_00001_0_3.0_12288_.zip
Eval num_timesteps=20480, episode_reward=0.00 +/- 0.00
Total episodes ran=1
Optimizing...
     pol_surr |    pol_entpen |       vf_loss |            kl |           ent
     -0.00024 |      -0.00043 |       0.00017 |       0.00039 |       4.29598
     -0.00601 |      -0.00043 |      8.46e-05 |       0.00472 |       4.29249
     -0.00825 |      -0.00043 |      6.66e-05 |       0.01417 |       4.27739
     -0.01111 |      -0.00043 |       0.00012 |       0.01544 |       4.27912
Evaluating losses...
     -0.01288 |      -0.00043 |      4.66e-05 |       0.01409 |       4.28754
------------------------------------
| EpLenMean       | 2.23e+03       |
| EpRewMean       | 0              |
| EpThisIter      | 2              |
| EpisodesSoFar   | 11             |
| TimeElapsed     | 4.14e+03       |
| TimestepsSoFar  | 24576          |
| ev_tdlam_before | 0.245          |
| loss_ent        | 4.2875414      |
| loss_kl         | 0.014085675    |
| loss_pol_entpen | -0.00042875417 |
| loss_pol_surr   | -0.012876825   |
| loss_vf_loss    | 4.656129e-05   |
------------------------------------
********** Iteration 6 ************
Eval num_timesteps=24576, episode_reward=0.00 +/- 0.00
Total episodes ran=1
